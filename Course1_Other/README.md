# Course 1 - Assigments

## Week2

### Python Basics with Numpy (optional assignment)

Welcome to your first assignment. This exercise gives you a brief introduction to Python. Even if you've used Python before, this will help familiarize you with functions we'll need.

Instructions:

     You will be using Python 3.
     Avoid using for-loops and while-loops, unless you are explicitly told to do so.
     Do not modify the (# GRADED FUNCTION [function name]) comment in some cells. Your
    work would not be graded if you change this. Each cell containing that comment should
    only contain one function.
     After coding your function, run the cell right below it to check if your result is correct.

After this assignment you will:

     Be able to use iPython Notebooks
     Be able to use numpy functions and numpy matrix/vector operations
     Understand the concept of "broadcasting"
     Be able to vectorize code

### Logistic Regression with a Neural Network mindset

Welcome to your first (required) programming assignment! You will build a logistic regression classifier to recognize cats. This assignment will step you through how to do this with a Neural Network mindset, and so will also hone your intuitions about deep learning.

Instructions:

    Do not use loops (for/while) in your code, unless the instructions explicitly ask you to do so.

You will learn to:

    Build the general architecture of a learning algorithm, including:
        Initializing parameters
        Calculating the cost function and its gradient
        Using an optimization algorithm (gradient descent)
    Gather all three functions above into a main model function, in the right order.

## Week3

### Planar data classification with one hidden layer

Welcome to your week 3 programming assignment. It's time to build your first neural network, which will have a hidden layer. You will see a big difference between this model and the one you implemented using logistic regression.

You will learn how to:

     Implement a 2-class classification neural network with a single hidden layer
     Use units with a non-linear activation function, such as tanh
     Compute the cross entropy loss
     Implement forward and backward propagation
